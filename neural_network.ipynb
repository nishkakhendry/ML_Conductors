{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy.linalg as LA\n",
    "from copy import deepcopy\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "DATA_PATH = './nomad2018-predict-transparent-conductors'\n",
    "\n",
    "def custom_converter(entry):\n",
    "    return np.array([float(x) for x in entry[1:-1].split(',')])\n",
    "\n",
    "train_all_data = pd.read_csv(\n",
    "    f'{DATA_PATH}/train_extrainfo.csv',\n",
    "    converters={\n",
    "        'CoulombMatrix':custom_converter,\n",
    "        'SineMatrix':custom_converter,\n",
    "        'EwaldSumMatrix':custom_converter\n",
    "    }\n",
    ")\n",
    "test_all_data = pd.read_csv(\n",
    "    f'{DATA_PATH}/test_extrainfo.csv',\n",
    "    converters={\n",
    "        'CoulombMatrix':custom_converter,\n",
    "        'SineMatrix':custom_converter,\n",
    "        'EwaldSumMatrix':custom_converter\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "train_all_data.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['id', 'spacegroup', 'number_of_total_atoms', 'percent_atom_al',\n",
       "       'percent_atom_ga', 'percent_atom_in', 'lattice_vector_1_ang',\n",
       "       'lattice_vector_2_ang', 'lattice_vector_3_ang',\n",
       "       'lattice_angle_alpha_degree', 'lattice_angle_beta_degree',\n",
       "       'lattice_angle_gamma_degree', 'formation_energy_ev_natom',\n",
       "       'bandgap_energy_ev', 'CoulombMatrix', 'SineMatrix', 'EwaldSumMatrix'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "\n",
    "def get_eigenspectrum(matrix):\n",
    "    spectrum = LA.eigvalsh(matrix)\n",
    "    spectrum = np.sort(spectrum)[::-1]\n",
    "    return spectrum\n",
    "\n",
    "def preprocess(data, train=True):\n",
    "    data = deepcopy(data)\n",
    "    spectrum_list = []\n",
    "    for m in data['SineMatrix']:\n",
    "        spectrum_list.append(\n",
    "            get_eigenspectrum(\n",
    "                np.reshape(m, (80, 80))\n",
    "            )\n",
    "        )\n",
    "    spectrum_df = pd.DataFrame(spectrum_list).astype(float)\n",
    "    if train:\n",
    "        to_drop = ['id', 'formation_energy_ev_natom', 'bandgap_energy_ev',\n",
    "                'CoulombMatrix', 'SineMatrix', 'EwaldSumMatrix']\n",
    "    else:\n",
    "        to_drop = ['id',\n",
    "               'CoulombMatrix', 'SineMatrix', 'EwaldSumMatrix']\n",
    "    dfcombined = pd.concat([data, spectrum_df], axis=1).drop(to_drop, axis=1)\n",
    "    return dfcombined\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "target_cols = ['formation_energy_ev_natom','bandgap_energy_ev']\n",
    "data = preprocess(train_all_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, train_all_data[target_cols], test_size = 0.30, random_state=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spacegroup</th>\n",
       "      <th>number_of_total_atoms</th>\n",
       "      <th>percent_atom_al</th>\n",
       "      <th>percent_atom_ga</th>\n",
       "      <th>percent_atom_in</th>\n",
       "      <th>lattice_vector_1_ang</th>\n",
       "      <th>lattice_vector_2_ang</th>\n",
       "      <th>lattice_vector_3_ang</th>\n",
       "      <th>lattice_angle_alpha_degree</th>\n",
       "      <th>lattice_angle_beta_degree</th>\n",
       "      <th>...</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>206</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>9.5583</td>\n",
       "      <td>9.5583</td>\n",
       "      <td>9.5580</td>\n",
       "      <td>90.0045</td>\n",
       "      <td>90.0040</td>\n",
       "      <td>...</td>\n",
       "      <td>51.278905</td>\n",
       "      <td>51.192050</td>\n",
       "      <td>50.684798</td>\n",
       "      <td>50.255256</td>\n",
       "      <td>49.243095</td>\n",
       "      <td>48.444891</td>\n",
       "      <td>48.437744</td>\n",
       "      <td>47.624117</td>\n",
       "      <td>41.435008</td>\n",
       "      <td>39.785544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>206</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>9.5382</td>\n",
       "      <td>9.5379</td>\n",
       "      <td>9.5380</td>\n",
       "      <td>90.0024</td>\n",
       "      <td>90.0027</td>\n",
       "      <td>...</td>\n",
       "      <td>48.124473</td>\n",
       "      <td>47.073484</td>\n",
       "      <td>46.151431</td>\n",
       "      <td>44.098866</td>\n",
       "      <td>41.950107</td>\n",
       "      <td>40.599060</td>\n",
       "      <td>39.816876</td>\n",
       "      <td>38.936680</td>\n",
       "      <td>37.261905</td>\n",
       "      <td>34.584100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>33</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>5.3302</td>\n",
       "      <td>9.1151</td>\n",
       "      <td>9.7342</td>\n",
       "      <td>89.9979</td>\n",
       "      <td>89.9997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>33</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>11.0070</td>\n",
       "      <td>9.3773</td>\n",
       "      <td>9.9993</td>\n",
       "      <td>89.9990</td>\n",
       "      <td>89.9976</td>\n",
       "      <td>...</td>\n",
       "      <td>53.141250</td>\n",
       "      <td>52.234727</td>\n",
       "      <td>52.214577</td>\n",
       "      <td>51.469821</td>\n",
       "      <td>51.383424</td>\n",
       "      <td>50.551757</td>\n",
       "      <td>47.950949</td>\n",
       "      <td>47.940750</td>\n",
       "      <td>47.005041</td>\n",
       "      <td>45.728682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>206</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.0894</td>\n",
       "      <td>9.0888</td>\n",
       "      <td>9.0890</td>\n",
       "      <td>90.0034</td>\n",
       "      <td>90.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>38.356714</td>\n",
       "      <td>37.568985</td>\n",
       "      <td>36.881481</td>\n",
       "      <td>35.529089</td>\n",
       "      <td>34.133708</td>\n",
       "      <td>33.929112</td>\n",
       "      <td>31.491647</td>\n",
       "      <td>31.410154</td>\n",
       "      <td>30.403501</td>\n",
       "      <td>23.782710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>167</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>5.4918</td>\n",
       "      <td>5.4913</td>\n",
       "      <td>14.5600</td>\n",
       "      <td>89.9984</td>\n",
       "      <td>89.9993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>33</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>10.7770</td>\n",
       "      <td>9.1878</td>\n",
       "      <td>9.8151</td>\n",
       "      <td>90.0022</td>\n",
       "      <td>89.9990</td>\n",
       "      <td>...</td>\n",
       "      <td>51.358700</td>\n",
       "      <td>50.391844</td>\n",
       "      <td>49.539896</td>\n",
       "      <td>49.029609</td>\n",
       "      <td>48.132958</td>\n",
       "      <td>47.697284</td>\n",
       "      <td>46.699077</td>\n",
       "      <td>46.315230</td>\n",
       "      <td>46.134322</td>\n",
       "      <td>42.784553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>12</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>24.3195</td>\n",
       "      <td>6.2018</td>\n",
       "      <td>6.0952</td>\n",
       "      <td>89.9996</td>\n",
       "      <td>104.7008</td>\n",
       "      <td>...</td>\n",
       "      <td>40.919317</td>\n",
       "      <td>40.599176</td>\n",
       "      <td>38.824526</td>\n",
       "      <td>36.662027</td>\n",
       "      <td>35.667331</td>\n",
       "      <td>32.352772</td>\n",
       "      <td>29.573998</td>\n",
       "      <td>25.913214</td>\n",
       "      <td>24.889890</td>\n",
       "      <td>23.723443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>167</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>5.2158</td>\n",
       "      <td>5.2154</td>\n",
       "      <td>13.9784</td>\n",
       "      <td>89.9940</td>\n",
       "      <td>90.0058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>12</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>24.7160</td>\n",
       "      <td>6.5275</td>\n",
       "      <td>6.5440</td>\n",
       "      <td>90.0003</td>\n",
       "      <td>105.4012</td>\n",
       "      <td>...</td>\n",
       "      <td>48.229816</td>\n",
       "      <td>46.007868</td>\n",
       "      <td>43.207590</td>\n",
       "      <td>43.093109</td>\n",
       "      <td>41.523991</td>\n",
       "      <td>34.572891</td>\n",
       "      <td>33.415265</td>\n",
       "      <td>30.085081</td>\n",
       "      <td>29.948745</td>\n",
       "      <td>28.716507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spacegroup  number_of_total_atoms  percent_atom_al  percent_atom_ga  \\\n",
       "60           206                   80.0           0.0938           0.6875   \n",
       "2079         206                   80.0           0.4062           0.2500   \n",
       "1395          33                   40.0           0.0000           0.6250   \n",
       "2227          33                   80.0           0.0000           0.3125   \n",
       "701          206                   80.0           0.7500           0.2500   \n",
       "...          ...                    ...              ...              ...   \n",
       "960          167                   30.0           0.0000           0.1667   \n",
       "905           33                   80.0           0.3438           0.0312   \n",
       "1096          12                   80.0           0.5000           0.1875   \n",
       "235          167                   30.0           0.4167           0.0833   \n",
       "1061          12                   80.0           0.0312           0.3125   \n",
       "\n",
       "      percent_atom_in  lattice_vector_1_ang  lattice_vector_2_ang  \\\n",
       "60             0.2188                9.5583                9.5583   \n",
       "2079           0.3438                9.5382                9.5379   \n",
       "1395           0.3750                5.3302                9.1151   \n",
       "2227           0.6875               11.0070                9.3773   \n",
       "701            0.0000                9.0894                9.0888   \n",
       "...               ...                   ...                   ...   \n",
       "960            0.8333                5.4918                5.4913   \n",
       "905            0.6250               10.7770                9.1878   \n",
       "1096           0.3125               24.3195                6.2018   \n",
       "235            0.5000                5.2158                5.2154   \n",
       "1061           0.6562               24.7160                6.5275   \n",
       "\n",
       "      lattice_vector_3_ang  lattice_angle_alpha_degree  \\\n",
       "60                  9.5580                     90.0045   \n",
       "2079                9.5380                     90.0024   \n",
       "1395                9.7342                     89.9979   \n",
       "2227                9.9993                     89.9990   \n",
       "701                 9.0890                     90.0034   \n",
       "...                    ...                         ...   \n",
       "960                14.5600                     89.9984   \n",
       "905                 9.8151                     90.0022   \n",
       "1096                6.0952                     89.9996   \n",
       "235                13.9784                     89.9940   \n",
       "1061                6.5440                     90.0003   \n",
       "\n",
       "      lattice_angle_beta_degree  ...         70         71         72  \\\n",
       "60                      90.0040  ...  51.278905  51.192050  50.684798   \n",
       "2079                    90.0027  ...  48.124473  47.073484  46.151431   \n",
       "1395                    89.9997  ...   0.000000   0.000000   0.000000   \n",
       "2227                    89.9976  ...  53.141250  52.234727  52.214577   \n",
       "701                     90.0041  ...  38.356714  37.568985  36.881481   \n",
       "...                         ...  ...        ...        ...        ...   \n",
       "960                     89.9993  ...   0.000000   0.000000   0.000000   \n",
       "905                     89.9990  ...  51.358700  50.391844  49.539896   \n",
       "1096                   104.7008  ...  40.919317  40.599176  38.824526   \n",
       "235                     90.0058  ...   0.000000   0.000000   0.000000   \n",
       "1061                   105.4012  ...  48.229816  46.007868  43.207590   \n",
       "\n",
       "             73         74         75         76         77         78  \\\n",
       "60    50.255256  49.243095  48.444891  48.437744  47.624117  41.435008   \n",
       "2079  44.098866  41.950107  40.599060  39.816876  38.936680  37.261905   \n",
       "1395   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2227  51.469821  51.383424  50.551757  47.950949  47.940750  47.005041   \n",
       "701   35.529089  34.133708  33.929112  31.491647  31.410154  30.403501   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "960    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "905   49.029609  48.132958  47.697284  46.699077  46.315230  46.134322   \n",
       "1096  36.662027  35.667331  32.352772  29.573998  25.913214  24.889890   \n",
       "235    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1061  43.093109  41.523991  34.572891  33.415265  30.085081  29.948745   \n",
       "\n",
       "             79  \n",
       "60    39.785544  \n",
       "2079  34.584100  \n",
       "1395   0.000000  \n",
       "2227  45.728682  \n",
       "701   23.782710  \n",
       "...         ...  \n",
       "960    0.000000  \n",
       "905   42.784553  \n",
       "1096  23.723443  \n",
       "235    0.000000  \n",
       "1061  28.716507  \n",
       "\n",
       "[1680 rows x 91 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "X_train.to_numpy().shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1680, 91)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(91, activation='relu'),\n",
    "    layers.Dense(180, activation='relu'),\n",
    "    layers.Dense(160, activation='relu'),\n",
    "    layers.Dense(150, activation='relu'),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(90, activation='relu'),\n",
    "    layers.Dense(80, activation='relu'),\n",
    "    layers.Dense(60, activation='relu'),\n",
    "    layers.Dense(50, activation='relu'),\n",
    "    layers.Dense(30, activation='relu'),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(2),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, validation_data=(X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/150\n",
      "53/53 [==============================] - 1s 5ms/step - loss: 74.5180 - accuracy: 0.7220 - val_loss: 1.2226 - val_accuracy: 0.9764\n",
      "Epoch 2/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.9244 - accuracy: 0.9804 - val_loss: 0.8316 - val_accuracy: 0.9847\n",
      "Epoch 3/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.8889 - accuracy: 0.9732 - val_loss: 1.0668 - val_accuracy: 0.9847\n",
      "Epoch 4/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.7842 - accuracy: 0.9780 - val_loss: 0.7015 - val_accuracy: 0.9792\n",
      "Epoch 5/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.9833 - val_loss: 0.6481 - val_accuracy: 0.9847\n",
      "Epoch 6/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.9821 - val_loss: 0.6270 - val_accuracy: 0.9069\n",
      "Epoch 7/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.9744 - val_loss: 0.4781 - val_accuracy: 0.9847\n",
      "Epoch 8/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.9833 - val_loss: 0.3818 - val_accuracy: 0.9847\n",
      "Epoch 9/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.9804 - val_loss: 0.3629 - val_accuracy: 0.9819\n",
      "Epoch 10/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.9833 - val_loss: 0.3184 - val_accuracy: 0.9847\n",
      "Epoch 11/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.9887 - val_loss: 0.2730 - val_accuracy: 0.9847\n",
      "Epoch 12/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.9875 - val_loss: 0.2713 - val_accuracy: 0.9833\n",
      "Epoch 13/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9863 - val_loss: 0.2611 - val_accuracy: 0.9847\n",
      "Epoch 14/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1991 - accuracy: 0.9881 - val_loss: 0.2255 - val_accuracy: 0.9847\n",
      "Epoch 15/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9887 - val_loss: 0.2208 - val_accuracy: 0.9847\n",
      "Epoch 16/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9869 - val_loss: 0.2570 - val_accuracy: 0.9847\n",
      "Epoch 17/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9893 - val_loss: 0.2025 - val_accuracy: 0.9847\n",
      "Epoch 18/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9893 - val_loss: 0.2035 - val_accuracy: 0.9847\n",
      "Epoch 19/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9887 - val_loss: 0.1613 - val_accuracy: 0.9847\n",
      "Epoch 20/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9893 - val_loss: 0.1718 - val_accuracy: 0.9847\n",
      "Epoch 21/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9893 - val_loss: 0.1455 - val_accuracy: 0.9847\n",
      "Epoch 22/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.9899 - val_loss: 0.1423 - val_accuracy: 0.9847\n",
      "Epoch 23/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9893 - val_loss: 0.1769 - val_accuracy: 0.9847\n",
      "Epoch 24/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9887 - val_loss: 0.1465 - val_accuracy: 0.9847\n",
      "Epoch 25/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9887 - val_loss: 0.1642 - val_accuracy: 0.9847\n",
      "Epoch 26/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9893 - val_loss: 0.1161 - val_accuracy: 0.9847\n",
      "Epoch 27/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9893 - val_loss: 0.1351 - val_accuracy: 0.9847\n",
      "Epoch 28/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9887 - val_loss: 0.1483 - val_accuracy: 0.9847\n",
      "Epoch 29/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9881 - val_loss: 0.1646 - val_accuracy: 0.9847\n",
      "Epoch 30/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9893 - val_loss: 0.1301 - val_accuracy: 0.9847\n",
      "Epoch 31/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9893 - val_loss: 0.1296 - val_accuracy: 0.9847\n",
      "Epoch 32/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9893 - val_loss: 0.1303 - val_accuracy: 0.9847\n",
      "Epoch 33/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9893 - val_loss: 0.1563 - val_accuracy: 0.9847\n",
      "Epoch 34/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9881 - val_loss: 0.1132 - val_accuracy: 0.9847\n",
      "Epoch 35/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9893 - val_loss: 0.1251 - val_accuracy: 0.9847\n",
      "Epoch 36/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9905 - val_loss: 0.1169 - val_accuracy: 0.9847\n",
      "Epoch 37/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.9893 - val_loss: 0.1587 - val_accuracy: 0.9847\n",
      "Epoch 38/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9881 - val_loss: 0.1833 - val_accuracy: 0.9778\n",
      "Epoch 39/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9893 - val_loss: 0.1246 - val_accuracy: 0.9847\n",
      "Epoch 40/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9881 - val_loss: 0.1157 - val_accuracy: 0.9847\n",
      "Epoch 41/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0981 - accuracy: 0.9887 - val_loss: 0.1203 - val_accuracy: 0.9847\n",
      "Epoch 42/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9893 - val_loss: 0.1260 - val_accuracy: 0.9847\n",
      "Epoch 43/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9893 - val_loss: 0.1008 - val_accuracy: 0.9847\n",
      "Epoch 44/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9887 - val_loss: 0.1471 - val_accuracy: 0.9819\n",
      "Epoch 45/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9899 - val_loss: 0.1111 - val_accuracy: 0.9847\n",
      "Epoch 46/150\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9893 - val_loss: 0.1441 - val_accuracy: 0.9847\n",
      "Epoch 47/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9893 - val_loss: 0.1221 - val_accuracy: 0.9847\n",
      "Epoch 48/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9893 - val_loss: 0.1183 - val_accuracy: 0.9847\n",
      "Epoch 49/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9893 - val_loss: 0.0942 - val_accuracy: 0.9847\n",
      "Epoch 50/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9893 - val_loss: 0.0983 - val_accuracy: 0.9847\n",
      "Epoch 51/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9899 - val_loss: 0.1000 - val_accuracy: 0.9847\n",
      "Epoch 52/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9887 - val_loss: 0.1648 - val_accuracy: 0.9847\n",
      "Epoch 53/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9881 - val_loss: 0.1201 - val_accuracy: 0.9847\n",
      "Epoch 54/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9887 - val_loss: 0.1122 - val_accuracy: 0.9847\n",
      "Epoch 55/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9887 - val_loss: 0.1178 - val_accuracy: 0.9847\n",
      "Epoch 56/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9893 - val_loss: 0.0948 - val_accuracy: 0.9847\n",
      "Epoch 57/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9905 - val_loss: 0.0925 - val_accuracy: 0.9861\n",
      "Epoch 58/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9887 - val_loss: 0.1110 - val_accuracy: 0.9847\n",
      "Epoch 59/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9893 - val_loss: 0.1168 - val_accuracy: 0.9847\n",
      "Epoch 60/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9887 - val_loss: 0.1059 - val_accuracy: 0.9847\n",
      "Epoch 61/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9893 - val_loss: 0.0956 - val_accuracy: 0.9847\n",
      "Epoch 62/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9869 - val_loss: 0.1439 - val_accuracy: 0.9847\n",
      "Epoch 63/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9899 - val_loss: 0.0816 - val_accuracy: 0.9847\n",
      "Epoch 64/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9899 - val_loss: 0.1016 - val_accuracy: 0.9847\n",
      "Epoch 65/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9899 - val_loss: 0.1106 - val_accuracy: 0.9847\n",
      "Epoch 66/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9893 - val_loss: 0.1319 - val_accuracy: 0.9847\n",
      "Epoch 67/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9911 - val_loss: 0.0907 - val_accuracy: 0.9847\n",
      "Epoch 68/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9881 - val_loss: 0.0943 - val_accuracy: 0.9847\n",
      "Epoch 69/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9893 - val_loss: 0.0888 - val_accuracy: 0.9847\n",
      "Epoch 70/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9887 - val_loss: 0.1158 - val_accuracy: 0.9847\n",
      "Epoch 71/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9887 - val_loss: 0.0947 - val_accuracy: 0.9847\n",
      "Epoch 72/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9887 - val_loss: 0.1177 - val_accuracy: 0.9847\n",
      "Epoch 73/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9893 - val_loss: 0.1070 - val_accuracy: 0.9847\n",
      "Epoch 74/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9893 - val_loss: 0.1154 - val_accuracy: 0.9847\n",
      "Epoch 75/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9893 - val_loss: 0.0970 - val_accuracy: 0.9847\n",
      "Epoch 76/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9887 - val_loss: 0.0893 - val_accuracy: 0.9847\n",
      "Epoch 77/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9875 - val_loss: 0.1033 - val_accuracy: 0.9847\n",
      "Epoch 78/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9899 - val_loss: 0.0927 - val_accuracy: 0.9847\n",
      "Epoch 79/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9881 - val_loss: 0.0844 - val_accuracy: 0.9847\n",
      "Epoch 80/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9875 - val_loss: 0.1116 - val_accuracy: 0.9847\n",
      "Epoch 81/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9881 - val_loss: 0.1001 - val_accuracy: 0.9847\n",
      "Epoch 82/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9875 - val_loss: 0.0902 - val_accuracy: 0.9847\n",
      "Epoch 83/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9887 - val_loss: 0.0877 - val_accuracy: 0.9833\n",
      "Epoch 84/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9875 - val_loss: 0.0959 - val_accuracy: 0.9847\n",
      "Epoch 85/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9899 - val_loss: 0.0847 - val_accuracy: 0.9847\n",
      "Epoch 86/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9893 - val_loss: 0.0806 - val_accuracy: 0.9847\n",
      "Epoch 87/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9899 - val_loss: 0.0940 - val_accuracy: 0.9847\n",
      "Epoch 88/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9893 - val_loss: 0.0860 - val_accuracy: 0.9847\n",
      "Epoch 89/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9893 - val_loss: 0.0788 - val_accuracy: 0.9847\n",
      "Epoch 90/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9887 - val_loss: 0.0767 - val_accuracy: 0.9847\n",
      "Epoch 91/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9875 - val_loss: 0.1013 - val_accuracy: 0.9847\n",
      "Epoch 92/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9887 - val_loss: 0.0830 - val_accuracy: 0.9833\n",
      "Epoch 93/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9887 - val_loss: 0.0784 - val_accuracy: 0.9847\n",
      "Epoch 94/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9893 - val_loss: 0.0789 - val_accuracy: 0.9833\n",
      "Epoch 95/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 0.0765 - val_accuracy: 0.9847\n",
      "Epoch 96/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9887 - val_loss: 0.0790 - val_accuracy: 0.9847\n",
      "Epoch 97/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9887 - val_loss: 0.0863 - val_accuracy: 0.9847\n",
      "Epoch 98/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9893 - val_loss: 0.0988 - val_accuracy: 0.9833\n",
      "Epoch 99/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9893 - val_loss: 0.0889 - val_accuracy: 0.9847\n",
      "Epoch 100/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9893 - val_loss: 0.0858 - val_accuracy: 0.9847\n",
      "Epoch 101/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9905 - val_loss: 0.0943 - val_accuracy: 0.9847\n",
      "Epoch 102/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9899 - val_loss: 0.0843 - val_accuracy: 0.9847\n",
      "Epoch 103/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9893 - val_loss: 0.0827 - val_accuracy: 0.9847\n",
      "Epoch 104/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9899 - val_loss: 0.0781 - val_accuracy: 0.9792\n",
      "Epoch 105/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9893 - val_loss: 0.0846 - val_accuracy: 0.9847\n",
      "Epoch 106/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9899 - val_loss: 0.0837 - val_accuracy: 0.9847\n",
      "Epoch 107/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9899 - val_loss: 0.0797 - val_accuracy: 0.9847\n",
      "Epoch 108/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9893 - val_loss: 0.0736 - val_accuracy: 0.9847\n",
      "Epoch 109/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9899 - val_loss: 0.0803 - val_accuracy: 0.9847\n",
      "Epoch 110/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9899 - val_loss: 0.0693 - val_accuracy: 0.9847\n",
      "Epoch 111/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9899 - val_loss: 0.0695 - val_accuracy: 0.9847\n",
      "Epoch 112/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9899 - val_loss: 0.0772 - val_accuracy: 0.9847\n",
      "Epoch 113/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9905 - val_loss: 0.0737 - val_accuracy: 0.9847\n",
      "Epoch 114/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9893 - val_loss: 0.0742 - val_accuracy: 0.9861\n",
      "Epoch 115/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9893 - val_loss: 0.0806 - val_accuracy: 0.9847\n",
      "Epoch 116/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9893 - val_loss: 0.0751 - val_accuracy: 0.9833\n",
      "Epoch 117/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9905 - val_loss: 0.0838 - val_accuracy: 0.9847\n",
      "Epoch 118/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9899 - val_loss: 0.0737 - val_accuracy: 0.9833\n",
      "Epoch 119/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9899 - val_loss: 0.0746 - val_accuracy: 0.9847\n",
      "Epoch 120/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9899 - val_loss: 0.0655 - val_accuracy: 0.9861\n",
      "Epoch 121/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9905 - val_loss: 0.0653 - val_accuracy: 0.9847\n",
      "Epoch 122/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9893 - val_loss: 0.0960 - val_accuracy: 0.9847\n",
      "Epoch 123/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9887 - val_loss: 0.0839 - val_accuracy: 0.9847\n",
      "Epoch 124/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9899 - val_loss: 0.0756 - val_accuracy: 0.9819\n",
      "Epoch 125/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9893 - val_loss: 0.0804 - val_accuracy: 0.9847\n",
      "Epoch 126/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9899 - val_loss: 0.0720 - val_accuracy: 0.9847\n",
      "Epoch 127/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9899 - val_loss: 0.0859 - val_accuracy: 0.9861\n",
      "Epoch 128/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9899 - val_loss: 0.0759 - val_accuracy: 0.9847\n",
      "Epoch 129/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9887 - val_loss: 0.0865 - val_accuracy: 0.9847\n",
      "Epoch 130/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9893 - val_loss: 0.0778 - val_accuracy: 0.9847\n",
      "Epoch 131/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0901 - val_accuracy: 0.9847\n",
      "Epoch 132/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9881 - val_loss: 0.0680 - val_accuracy: 0.9819\n",
      "Epoch 133/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9899 - val_loss: 0.0643 - val_accuracy: 0.9819\n",
      "Epoch 134/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9869 - val_loss: 0.0675 - val_accuracy: 0.9847\n",
      "Epoch 135/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9905 - val_loss: 0.0852 - val_accuracy: 0.9833\n",
      "Epoch 136/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.0795 - val_accuracy: 0.9847\n",
      "Epoch 137/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9881 - val_loss: 0.0721 - val_accuracy: 0.9847\n",
      "Epoch 138/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9893 - val_loss: 0.0764 - val_accuracy: 0.9847\n",
      "Epoch 139/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9887 - val_loss: 0.0841 - val_accuracy: 0.9847\n",
      "Epoch 140/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9893 - val_loss: 0.0743 - val_accuracy: 0.9847\n",
      "Epoch 141/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9887 - val_loss: 0.0600 - val_accuracy: 0.9847\n",
      "Epoch 142/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9881 - val_loss: 0.0904 - val_accuracy: 0.9792\n",
      "Epoch 143/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9887 - val_loss: 0.0672 - val_accuracy: 0.9847\n",
      "Epoch 144/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9893 - val_loss: 0.0639 - val_accuracy: 0.9847\n",
      "Epoch 145/150\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9887 - val_loss: 0.0695 - val_accuracy: 0.9847\n",
      "Epoch 146/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 0.0624 - val_accuracy: 0.9847\n",
      "Epoch 147/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 0.0699 - val_accuracy: 0.9847\n",
      "Epoch 148/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.0715 - val_accuracy: 0.9847\n",
      "Epoch 149/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.0611 - val_accuracy: 0.9833\n",
      "Epoch 150/150\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9875 - val_loss: 0.0674 - val_accuracy: 0.9861\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim([0, 5])\n",
    "plt.legend(loc='upper right')\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f78684a0390>"
      ]
     },
     "metadata": {},
     "execution_count": 90
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f78683ffb50>"
      ]
     },
     "metadata": {},
     "execution_count": 91
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqtUlEQVR4nO3deZxU1Zn/8c/TXb03dDfNToOAQUVERFBRM0o0ZDDjksQQ9GcWidGYjMZlfklcMtEYJ5OZJGM0o04w45YxmgTHhDiJSVD8mYyYCIobbggI3WxN0yv0Usvz++NWN9V7g11U4/2+X69+dd1bt249davufe45595zzN0REZHwysp0ACIikllKBCIiIadEICISckoEIiIhp0QgIhJySgQiIiGXtkRgZvea2U4ze7WX583M7jCz9Wb2spkdn65YRESkd+ksEdwPLOzj+bOAacm/y4C70xiLiIj0Im2JwN2fAXb3sch5wIMeeA4oNbNx6YpHRER6Fsnge08AtqRMVybnbeu6oJldRlBqoKioaM5RRx11UAIUEXm/WLNmzS53H9XTc5lMBAPm7kuBpQBz58711atXZzgiEZFDi5m929tzmbxqqAqYmDJdkZwnIiIHUSYTwXLgs8mrh+YB9e7erVpI0i+ecNZtbWBnQ0umQ+lXWyzBa1vr2dMaG5T1tcbi/O6VbfzPy9tIJNQBY7uWaJy1W+p4t2YPbbHEoK+/oSXKuq0NrN/ZSG8dX1Y3tvLi5lp2NrR0W6YtlmDTrj2s3VJHSzQ+6PH1pqaplZ2NQ38/2V9pqxoys4eB+cBIM6sEbgJyANz9P4DfAh8F1gN7gSXpiiUd3J1fr91KcV6EE6aMoKQgp+O5Lbv38sb2Rqpq9zKpvJDTpo2iuqmVpc9s4O0dTQAU5WUzsayQ7Gyjcncz9c1RABpbY1TV7mVvW5wJpQVUlBUwcUQho4flYWa0RuNU1jZT3dSKO2RnGeNL86koK6SirICSghzWbqnjpS11ROPddzAzmD5uOMdPKqOydi+r3qnhrxt305g8sE4dVcTJU8uZN7WcxpYYf91YQ35ONvOmljO8IEJlbTNbdu+lsraZxpbgNQW52VSUFdAaS/Dchhq217cwobSAUcPyyDLrdRu2xuJU1TZT1xzl2IoSTppSztRRRYwalkd1Yyvb61uIJZx4wtne0MKmXXt4cXMdzdE4RbnZnDVzHIW52VTVNlOUF6GirIC9bXGq6po5ZnwJSz44mbd3NPKNX73Gm9sbOr13sHwh2+qbqdsbbPu5h5Xxf06axIub69hW39zxGSzlM3Td/u2ysoxxw/OZVF7InMPKmFxexH3PbuTRNVUcN7GET86pYNbEUkYPy6exJcrWuhaGF0QYMzyfDdV7eH7TbkYW5zLnsBGsfGMndz29nvrmKBNHFBKNO5W1e8kyo6KsgNLCHAyjMDebiSMKmTa6OPn95PDchho27toDwN62WMf3NL40nzHD8snKSvkssQRb65rZ0dDS6bPsbYvxalUDbfFEx29m7PB8xpXkU7c3ytb6Zobn5zC+tICm1hhVtc20xoKDcVlhbsdvobK2mb1t3RO2Q6f3G1mcyxFjhnX6rWxvaGH9zqZOv9vUX1Jqzs6NZHFcRSlTRhZRWhj8/l+pqqesMJcxw/PYvaeNrfUtxOKJlPUZ00YXc9KUEQBU1jbTmkx4h5UXctLUct7Z2cSv11YxvrSAW86bwbs1e7n2Fy/RFktw7YIj+PS8w9je0MKrVfWs2lDDzoZWKsoKKMzNprK2mT2tMSaUJffhskJKCnLYWt/Clt172VK7l9o9bYwtyWfs8AIi2UY0nmBbXQvbGlo6nZRkZRmnTRvJx2ZPYGRxXrftORjsUOuGeqi0Edy5cj3f+/2bAGQZzBhfwgmTR/BqVT1/3dT5YqmRxXk0NEdJuDOzooQsM+qbo1TW7iWRgAllBZQV5mAW7NwVZQXk5wQHuMraZrbU7u046JrBuOH5jB6eT3aW0ZbcmWv2tHW8nxkcOWYYRXnd83xbLMGb2xs7dvLJ5YWcfHg5J0weQXVjK6s21PD8xt3saQt27FHD8miNxmlo2bdD50ayggNSQRBzY0uULbubyc4yTpwygkkjCrvF1JNIljGhtICivAgvbK5l3bYGevs5jijKZWJZASeNj3B6wQb+d/dwHngzQlZyHXvaYmytayE/khUcXHftoTgvQlNrjPEl+Xxs9gSyUw6CDc1RttQ2Myw/wieOr2BHQwv/9D+vU98cDQ6wZcFnaOxS8mg/KI5Jbv920XiCrXUt7Gpq7bTs/CNG8drWBnY2BvOzrPNBrDfHVpQwY3wJVXXNRLKMiWUFJJxOv4WG5iiVtc0093JGnJ1ljCvJpzgvwta65k7fYbsxw/MYW1JAJOWzRLKMWRNLOX5SKY0tsY7f4Pb6FsoKcxlXkk99c5AQhuXlMCF58HOHmj2tVNY2kxcJfsfD8ns+1yzOizBxRCFNzW1UrltFff1u3sg5mpjlAjA8P8KJU8r5wOhittc3U93YSvtmG95SxeiWd2HiCeQNK2fNu7WsebeWzbub2b2nlRnjS5idjH17fQvlxbmMLy1gGHuZ0PgStfmTqM6t4NWqela/u5ucrCwmlAW/w4Q7b+9ooqk1hhmcPLWcddsaaGqJEUs4M8YPZ+zwfJ58Y2e3zzO+NJ+q2mZaYgnGl+ZTlBuhqm7fCVPq72LMsHzKinLZ2dDSaT8ZWZzH+NJ8crL3VdY0tcR4a0c9iyJ/5qSFF3H+B4/t5VfTNzNb4+5ze3wudIlg+yuw4maItULRKPjo96GoHKrfovWpfyb33NuwglJoaYDHLofWBmJkkz33YmzGx2D7K1Qtv4XNlVWUD8uj+LDjWWXHsatqPZNrVzE6Zy+jivMoKcwhL5JFU0uM6qY2crKM8aXBAb6d4+B0OuPsTSLle+rpLDuecFpjcaJxpyg3m0h277V+cXf2tMbIi2SRF8nu9nzsxMt5bdgHKc6PMPW1O2HjM+xpi+Pu5EWyyMnO6hzzyGn46V/H80rJ+uvdsP7Jfj9Pj3F1fIYEOdlZ5EayaT8+ZZlBtBm2rYVEsGP5iMOx4eM7Xu/uYGAYTa0xttU3k5udRUVZYaeDdm+i8QStsTiFuRGyzHC8x8TUVyknFk/Q0BJjb1uMEUW5FOYGB5fGlijN0QRtsQSRLCMvkkUs4bTGErSUT6dk5kdp3rWZ+NsrGGGNHWf9/XGc5rYgUTdllxI5cgHjJkwme8MKspu2Y1Pnw4gp8M5TJKrWAikfKCefrCmnw/jj4N1VsHlVx7btUXYuzL8eJp4AbXvhd1+F2l7bH/vnDjVvQ9OOZDxFcPiH4Ii/heHj4e0V0FAJU+fDiMNhw0p46/dQ/UawvGXDuFmQW7RvlZF87KTLYdqHYfNz8OcfQltTt98O5R+AYeM6/WbaxafMZ91hn6a8tITxpQXUVG/jtUduYhhNzDj9fHIiEar++mu8dhN5kSwKc7M7/Wa67tNtwyay/oSbqGuLMLnldca+8G9kJaIdz/e6b2dlw8STYOxMWlZ+n/yda9lx0o2MOetrB7S5lQjaJRJwz/zgxztmBlSuhglz4JP/ScPdCxjeXMll2bdQfOTpfOu4Bob97ByaR0xnR00tk207rSOmk7P7Teq8kO15UzhqVB5Z21+GeJDRvaQCSicNaAcesuq2QPNu+NKzsPUF+OXFMGYm5A/veXl3qHwecgqgoAzq3oVxx3XaOQeNZQXf19TTYdd6eOcpaG3o/3VDWTwK216CeLIkMXwClE0+sHXt3gCNyWa2SD4UjgwOpABZOcFBM5JStbC3Zt9BFYOxMyFvWO/rr1kfHEgv+SM8+S1YtxwmnRyc4h6o4jEw7SNQUApv/yE40DckrxnJzoPi0VCfvMo8KwKHnQJHLAz2341/gsq/QiKlRFS3OVh+zEzY8QoUj4Xyw4PfTsVcmHI67Hor+dtp7B5PdC9sfTH4DqafA/EYvPxIcGKYVwwt9cFyeSUw5uhgvX1xDxLs9HNgwbfgJx8OPkf5B/rfNm17YPvL4IlgOy24BY5dfMDbW4mg3dqH4VeXc3f59Vx4ybWUvrMcHr2EaKSInFhQr3rPhH/iXzZO5cYPvMuSzdfxzdE/4tc7R3F+4g9cxO/4U2Im7x57NdeeeyLD8nOgtSn4oodPgNHT39tOMRTUbYa7Tgl+5DXroXQSXLICsvtoTtq1Hv7wjeDM7oxvwAfOPHjxvh+07Ql+Q8VjYMwxB/4bcg8OHHt2BQfonAKofjP4Tg87ueeDfN2WoJRccQIU93iJ+T4178BPzgwOjm2N8JFb4ZQrDyzWvj7DjleD39KkkyGnEHa9DbUbYdI8yC/p+/WxVnjuLnjhpzDjY/A3/7D/JyXvrAx+zzXvBNMTT4SF34WRRwQnPZ4I5mXn9L2eds/+O/zhRsgdFpzlX/pUkJwGYu9uqFoTlAx6OxkbICUCCHa2H82h2so5ced1fOL4SfzgU7PY/NjNVKz9IQ8P+ywXNT0AH/8x/1w1i+1/fpDbc+/iQ60/4KKPnsHCY8bykz9tZOExY5k3tXzwP9hQsuYB+M1XgjOyLz4Do3UDnyRt+jP89OMw60I45/ZD/8TnYHCHx6+BtQ/Bp/8bpvxNRsLoKxEcEjeUDYpVd0LjNlbN+Q6+M4tHX6hk4ogClr44jyNKHuK+zx4Pdz4ALfV85cxp3P1CFGJQMKyMT887jPycbG4+d0amP8XBcfxng9LA2JlKAtLZ5A/C/307ODNXEhgYMzj7NvjwzUEV2BAUnkRw/OegaBRVTbOAN5hcXsgPV7zN1FFFLL1sHmWFyUbTlgaK8iKce2QxvAafP+O4Tg28oWAGH/l2pqOQoWqIHsyGNLMhvd3CMx7BsDEwd0nHtcR3XDibj8+ewMOXzmP0sPygvi+nEFrqADiiNIFn5/PJeQOsyxMROUSFp0SQFEtexD1zQgm3LT6u85N5w/ddhdJSj73HxhkRkUNBeEoESbFEguws6/na/fySfZeHtTT0f4WCiMj7QPgSQdw73UXZSf7wIAFAkBBUIhCREAhfIkj0kQjyhu8rEbQ2BNMiIu9z4UsE8UTv3S/kl3RqI1DVkIiEQegSQbSvEkH+8C5tBCoRiMj7X+gSQTzuRLJ7SwQlXdoIVCIQkfe/0CWCaCJBJKuXj503POj8q7URYs1Bx1IiIu9zoUsE8UQ/JQKA+srO0yIi72OhSwR9Xz6aPPDXJbu9VRuBiIRA6BJB+6AnPeooEWzuPC0i8j4WukQQT3jvo1W13zfQXiLQfQQiEgKhSwTRhPd9HwHsGxFJJQIRCYHQJYJYPEFOX/cRgNoIRCRUwpcIBlI1VK+qIREJj/Algr4ai3OLg8GoG7cDpkQgIqEQvkTQ130EWVnJAb49+N/bjWciIu8joTvS9XkfAexrIFZDsYiERPgSQV9dTMC+biVULSQiIRG+RNBXp3OgEoGIhE74EkFf3VDDvktGdemoiIRE+BJBXwPTgEoEIhI6oUsE0YST01fVUHvbgNoIRCQkQpcI+uxrCFQiEJHQCV0iiMb7uWpIbQQiEjKhSwSxeD9VQyoRiEjIhC4RBFVDfd1HoDYCEQmX0CWCaCLRd4mgoDT4rxKBiIREWhOBmS00szfNbL2ZXdfD84eZ2ZNm9rKZPW1mFemMJ55w3Om7jWDSKbDgFpj8N+kMRURkyEhbIjCzbOBO4CzgaOBCMzu6y2LfBx5092OBW4B/Tlc8EHQvAfR9Z3EkF069KvgvIhIC6SwRnAisd/cN7t4GPAKc12WZo4Gnko9X9vD8oIrFHaDvO4tFREImnYlgArAlZboyOS/VS8Anko8/Dgwzs/KuKzKzy8xstZmtrq6uPuCAYokgEfR5H4GISMhkurH4/wKnm9mLwOlAFRDvupC7L3X3ue4+d9SoUQf8ZrF4UDXU68A0IiIhFEnjuquAiSnTFcl5Hdx9K8kSgZkVA+e7e126AmovEfTZRiAiEjLpPDV+HphmZlPMLBe4AFieuoCZjTSz9hiuB+5NYzz7EoGqhkREOqQtEbh7DLgC+D3wOvALd3/NzG4xs3OTi80H3jSzt4AxwD+lKx7YVzXU5+WjIiIhk86qIdz9t8Bvu8z7ZsrjZcCydMaQKhpX1ZCISFehOjWOd1QNhepji4j0KVRHxGh8ADeUiYiETKgSQXtjcZ99DYmIhEyoEkE82cVEn72PioiETKiOiO2NxTm6fFREpEOoEkFHX0O6s1hEpEOojoixjqohlQhERNqFKxHE1VgsItJVuBJBQncWi4h0FaojojqdExHpLlyJQAPTiIh0E6pEENV4BCIi3YTqiBjXCGUiIt2EKhFE1UYgItJNqBJBvL1qSFcNiYh0CNURsWPwepUIREQ6hCoR7OtrKFQfW0SkT6E6Irb3Pqo2AhGRfUKVCKK6j0BEpJtQJYJYIkF2lmGmRCAi0i5kicB1D4GISBfhSgRx16A0IiJdhCwRJDQojYhIF6E6KsYSroZiEZEuwpUI4q5LR0VEughVIogmEhqURkSki1AdFeMJlQhERLoKVSKIxdVGICLSVagSQTSe0KA0IiJdhOqoGNcNZSIi3YQqEUQTrvsIRES6CNVRMRZP6M5iEZEuwpUIVDUkItJNuBKBGotFRLpJ61HRzBaa2Ztmtt7Mruvh+UlmttLMXjSzl83so+mMR/cRiIh0l7ZEYGbZwJ3AWcDRwIVmdnSXxb4B/MLdZwMXAHelKx4IBqbRfQQiIp2ls0RwIrDe3Te4exvwCHBel2UcGJ58XAJsTWM8xNTFhIhIN+k8Kk4AtqRMVybnpboZ+LSZVQK/Ba7saUVmdpmZrTaz1dXV1QccUExVQyIi3WT69PhC4H53rwA+CvzUzLrF5O5L3X2uu88dNWrUAb+ZupgQEemu30RgZuf0dHAegCpgYsp0RXJeqkuAXwC4+yogHxh5AO81IBqYRkSku4EcFRcDb5vZv5rZUfux7ueBaWY2xcxyCRqDl3dZZjNwJoCZTSdIBAde99OPWMLJUdWQiEgn/SYCd/80MBt4B7jfzFYl6+yH9fO6GHAF8HvgdYKrg14zs1vM7NzkYv8AXGpmLwEPAxe7u7+Hz9Mn3VAmItJdZCALuXuDmS0DCoCrgY8DXzWzO9z9R3287rcEjcCp876Z8ngdcOoBxH1AonFdNSQi0tVA2gjONbPHgKeBHOBEdz8LmEVwRn/IiGvMYhGRbgZSIjgfuM3dn0md6e57zeyS9ISVHsGYxSoRiIikGkgiuBnY1j5hZgXAGHff5O5PpiuwdIgmEmosFhHpYiCnx78EEinT8eS8Q0oi4bijxmIRkS4GkggiyS4iAEg+zk1fSOkRTQS5TL2Pioh0NpCjYnXK5Z6Y2XnArvSFlB6xeHBVqhqLRUQ6G0gbweXAQ2b274AR9B/02bRGlQaxRJAIVDUkItJZv4nA3d8B5plZcXK6Ke1RpUEsrqohEZGeDOiGMjP7O2AGkG8WnFG7+y1pjGvQtZcI1PuoiEhnA7mh7D8I+hu6kqBqaBFwWJrjGnQdiUBVQyIinQyknuQUd/8sUOvu3wJOBo5Ib1iDr71qSF1MiIh0NpCjYkvy/14zGw9EgXHpCyk9onFVDYmI9GQgbQS/MbNS4HvACwTDS96TzqDSId5RNaQSgYhIqj4TQXJAmifdvQ541MweB/Ldvf5gBDeYou1VQyoRiIh00ufpsbsngDtTplsPxSQA+0oE6mtIRKSzgdSTPGlm51v7daOHqFiyi4lsVQ2JiHQykKPiFwk6mWs1swYzazSzhjTHNejaG4tzdPmoiEgnA7mzuM8hKQ8VHY3FurNYRKSTfhOBmZ3W0/yuA9UMde2NxeprSESks4FcPvrVlMf5wInAGuCMtESUJu29j6qxWESks4FUDZ2TOm1mE4EfpiugdInpPgIRkR4dyFGxEpg+2IGkW/tVQ7qPQESks4G0EfyI4G5iCBLHcQR3GB9SNDCNiEjPBtJGsDrlcQx42N3/N03xpE2s44YyVQ2JiKQaSCJYBrS4exzAzLLNrNDd96Y3tMEV01VDIiI9GtCdxUBBynQBsCI94aRPVAPTiIj0aCCJID91eMrk48L0hZQecY1HICLSo4EcFfeY2fHtE2Y2B2hOX0jpoaEqRUR6NpA2gquBX5rZVoKhKscSDF15SOnofVQlAhGRTszd+1/ILAc4Mjn5prtH0xpVH+bOneurV6/uf8EetH/WQ7wjVRGR/WZma9x9bk/PDWTw+r8Hitz9VXd/FSg2sy8PdpAHg5kpCYiIdDGQepJLkyOUAeDutcClaYtIREQOqoEkguzUQWnMLBvITV9IIiJyMA2ksfgJ4Odm9uPk9BeB36UvJBEROZgGkgi+DlwGXJ6cfpngyiEREXkf6LdqKDmA/V+ATQRjEZwBvD6QlZvZQjN708zWm9l1PTx/m5mtTf69ZWZ1+xW9iIi8Z72WCMzsCODC5N8u4OcA7v6hgaw42ZZwJ7CAoOvq581subuva1/G3a9JWf5KYPYBfAYREXkP+ioRvEFw9n+2u3/Q3X8ExPdj3ScC6919g7u3AY8A5/Wx/IXAw/uxfhERGQR9JYJPANuAlWZ2j5mdSXBn8UBNALakTFcm53VjZocBU4Cnenn+MjNbbWarq6ur9yMEERHpT6+JwN1/5e4XAEcBKwm6mhhtZneb2UcGOY4LgGXtXV33EMtSd5/r7nNHjRo1yG8tIhJuA2ks3uPuP0uOXVwBvEhwJVF/qoCJKdMVyXk9uQBVC4mIZMR+9cDm7rXJs/MzB7D488A0M5tiZrkEB/vlXRcys6OAMmDV/sQiIiKDI21dcbp7DLgC+D3B5aa/cPfXzOwWMzs3ZdELgEd8IL3fiYjIoBvIDWUHzN1/C/y2y7xvdpm+OZ0xiIhI39Q5v4hIyCkRiIiEnBKBiEjIKRGIiIScEoGISMgpEYiIhJwSgYhIyCkRiIiEnBKBiEjIKRGIiIScEoGISMgpEYiIhJwSgYhIyCkRiIiEnBKBiEjIKRGIiIScEoGISMgpEYiIhJwSgYhIyCkRiIiEnBKBiEjIKRGIiIScEoGISMgpEYiIhJwSgYhIyCkRiIiEnBKBiEjIKRGIiIScEoGISMgpEYiIhJwSgYhIyCkRiIiEnBKBiEjIKRGIiIRcWhOBmS00szfNbL2ZXdfLMp8ys3Vm9pqZ/Syd8YiISHeRdK3YzLKBO4EFQCXwvJktd/d1KctMA64HTnX3WjMbna54RESkZ+ksEZwIrHf3De7eBjwCnNdlmUuBO929FsDdd6YxHhER6UE6E8EEYEvKdGVyXqojgCPM7H/N7DkzW9jTiszsMjNbbWarq6ur0xSuiEg4ZbqxOAJMA+YDFwL3mFlp14Xcfam7z3X3uaNGjTq4EYqIvM+lMxFUARNTpiuS81JVAsvdPeruG4G3CBKDiIgcJOlMBM8D08xsipnlAhcAy7ss8yuC0gBmNpKgqmhDGmMSEZEu0pYI3D0GXAH8Hngd+IW7v2Zmt5jZucnFfg/UmNk6YCXwVXevSVdMIiLSnbl7pmPYL3PnzvXVq1dnOgwRSYpGo1RWVtLS0pLpUATIz8+noqKCnJycTvPNbI27z+3pNWm7j0BEwqGyspJhw4YxefJkzCzT4YSau1NTU0NlZSVTpkwZ8OsyfdWQiBziWlpaKC8vVxIYAsyM8vLy/S6dKRGIyHumJDB0HMh3oUQgIhJySgQiIiGnRCAiMkCxWCzTIaSFrhoSkUHzrd+8xrqtDYO6zqPHD+emc2b0u9zHPvYxtmzZQktLC1dddRWXXXYZTzzxBDfccAPxeJyRI0fy5JNP0tTUxJVXXsnq1asxM2666SbOP/98iouLaWpqAmDZsmU8/vjj3H///Vx88cXk5+fz4osvcuqpp3LBBRdw1VVX0dLSQkFBAffddx9HHnkk8Xicr3/96zzxxBNkZWVx6aWXMmPGDO644w5+9atfAfDHP/6Ru+66i8cee2xQt9F7pUQgIu8L9957LyNGjKC5uZkTTjiB8847j0svvZRnnnmGKVOmsHv3bgC+/e1vU1JSwiuvvAJAbW1tv+uurKzk2WefJTs7m4aGBv70pz8RiURYsWIFN9xwA48++ihLly5l06ZNrF27lkgkwu7duykrK+PLX/4y1dXVjBo1ivvuu4/Pf/7zad0OB0KJQEQGzUDO3NPljjvu6DjT3rJlC0uXLuW0007ruJ5+xIgRAKxYsYJHHnmk43VlZWX9rnvRokVkZ2cDUF9fz+c+9znefvttzIxoNNqx3ssvv5xIJNLp/T7zmc/wX//1XyxZsoRVq1bx4IMPDtInHjxKBCJyyHv66adZsWIFq1atorCwkPnz53PcccfxxhtvDHgdqZdddr0Ov6ioqOPxP/7jP/KhD32Ixx57jE2bNjF//vw+17tkyRLOOecc8vPzWbRoUUeiGErUWCwih7z6+nrKysooLCzkjTfe4LnnnqOlpYVnnnmGjRs3AnRUDS1YsIA777yz47XtVUNjxozh9ddfJ5FI9FmHX19fz4QJwdAq999/f8f8BQsW8OMf/7ijQbn9/caPH8/48eO59dZbWbJkyeB96EGkRCAih7yFCxcSi8WYPn061113HfPmzWPUqFEsXbqUT3ziE8yaNYvFixcD8I1vfIPa2lqOOeYYZs2axcqVKwH47ne/y9lnn80pp5zCuHHjen2vr33ta1x//fXMnj2701VEX/jCF5g0aRLHHnsss2bN4mc/2zcE+0UXXcTEiROZPn16mrbAe6NO50TkPXn99deH7AFuqLjiiiuYPXs2l1xyyUF5v56+E3U6JyKSIXPmzKGoqIgf/OAHmQ6lV0oEIiJptGbNmkyH0C+1EYiIhJwSgYhIyCkRiIiEnBKBiEjIKRGIiIScEoGIhEpxcXGmQxhydPmoiAye310H218Z3HWOnQlnfXdw1zkExGKxIdPvkEoEInJIu+666zr1HXTzzTdz6623cuaZZ3L88cczc+ZMfv3rXw9oXU1NTb2+7sEHH+zoPuIzn/kMADt27ODjH/84s2bNYtasWTz77LNs2rSJY445puN13//+97n55psBmD9/PldffTVz587l9ttv5ze/+Q0nnXQSs2fP5sMf/jA7duzoiGPJkiXMnDmTY489lkcffZR7772Xq6++umO999xzD9dcc82BbrbO3P2Q+pszZ46LyNCxbt26jL7/Cy+84KeddlrH9PTp033z5s1eX1/v7u7V1dV++OGHeyKRcHf3oqKiXtcVjUZ7fN2rr77q06ZN8+rqand3r6mpcXf3T33qU37bbbe5u3ssFvO6ujrfuHGjz5gxo2Od3/ve9/ymm25yd/fTTz/dv/SlL3U8t3v37o647rnnHr/22mvd3f1rX/uaX3XVVZ2Wa2xs9KlTp3pbW5u7u5988sn+8ssv9/g5evpOgNXey3F1aJRLREQO0OzZs9m5cydbt26lurqasrIyxo4dyzXXXMMzzzxDVlYWVVVV7Nixg7Fjx/a5Lnfnhhtu6Pa6p556ikWLFjFy5Ehg31gDTz31VMf4AtnZ2ZSUlPQ70E1753cQDHizePFitm3bRltbW8fYCb2NmXDGGWfw+OOPM336dKLRKDNnztzPrdUzJQIROeQtWrSIZcuWsX37dhYvXsxDDz1EdXU1a9asIScnh8mTJ3cbY6AnB/q6VJFIhEQi0THd19gGV155Jddeey3nnnsuTz/9dEcVUm++8IUv8J3vfIejjjpqULu0VhuBiBzyFi9ezCOPPMKyZctYtGgR9fX1jB49mpycHFauXMm77747oPX09rozzjiDX/7yl9TU1AD7xho488wzufvuuwGIx+PU19czZswYdu7cSU1NDa2trTz++ON9vl/72AYPPPBAx/zexkw46aST2LJlCz/72c+48MILB7p5+qVEICKHvBkzZtDY2MiECRMYN24cF110EatXr2bmzJk8+OCDHHXUUQNaT2+vmzFjBjfeeCOnn346s2bN4tprrwXg9ttvZ+XKlcycOZM5c+awbt06cnJy+OY3v8mJJ57IggUL+nzvm2++mUWLFjFnzpyOaifofcwEgE996lOceuqpAxpic6A0HoGIvCcaj+DgOvvss7nmmms488wze11mf8cjUIlAROQQUFdXxxFHHEFBQUGfSeBAqLFYRELnlVde6bgXoF1eXh5/+ctfMhRR/0pLS3nrrbfSsm4lAhF5z9wdM8t0GAM2c+ZM1q5dm+kw0uJAqvtVNSQi70l+fj41NTUHdACSweXu1NTUkJ+fv1+vU4lARN6TiooKKisrqa6uznQoQpCYKyoq9us1SgQi8p7k5OR03BErh6a0Vg2Z2UIze9PM1pvZdT08f7GZVZvZ2uTfF9IZj4iIdJe2EoGZZQN3AguASuB5M1vu7uu6LPpzd78iXXGIiEjf0lkiOBFY7+4b3L0NeAQ4L43vJyIiByCdbQQTgC0p05XAST0sd76ZnQa8BVzj7lu6LmBmlwGXJSebzOzNA4xpJLDrAF97sCjGwaEYB8dQj3GoxwdDJ8bDensi043FvwEedvdWM/si8ABwRteF3H0psPS9vpmZre7tFuuhQjEODsU4OIZ6jEM9Pjg0Ykxn1VAVMDFluiI5r4O717h7a3LyJ8CcNMYjIiI9SGcieB6YZmZTzCwXuABYnrqAmY1LmTwXeD2N8YiISA/SVjXk7jEzuwL4PZAN3Ovur5nZLQRDpi0HvmJm5wIxYDdwcbriSXrP1UsHgWIcHIpxcAz1GId6fHAIxHjIdUMtIiKDS30NiYiEnBKBiEjIhSYR9NfdRSaY2UQzW2lm68zsNTO7Kjl/hJn90czeTv4fvDHpDizObDN70cweT05PMbO/JLflz5MXA2QyvlIzW2Zmb5jZ62Z28hDchtckv+NXzexhM8vP9HY0s3vNbKeZvZoyr8ftZoE7krG+bGbHZzDG7yW/65fN7DEzK0157vpkjG+a2d9mKsaU5/7BzNzMRianM7Id+xOKRJDS3cVZwNHAhWZ2dGajAoJG8n9w96OBecDfJ+O6DnjS3acBTyanM+kqOl/R9S/Abe7+AaAWuCQjUe1zO/CEux8FzCKIdchsQzObAHwFmOvuxxBcPHEBmd+O9wMLu8zrbbudBUxL/l0G3J3BGP8IHOPuxxLciHo9QHLfuQCYkXzNXcl9PxMxYmYTgY8Am1NmZ2o79ikUiYAh2t2Fu29z9xeSjxsJDmATCGJ7ILnYA8DHMhIgYGYVwN8R3OeBBaOPnAEsSy6S6fhKgNOA/wRw9zZ3r2MIbcOkCFBgZhGgENhGhrejuz9DcLVeqt6223nAgx54Dijtcvn3QYvR3f/g7rHk5HME9yi1x/iIu7e6+0ZgPcG+f9BjTLoN+BqQekVORrZjf8KSCHrq7mJChmLpkZlNBmYDfwHGuPu25FPbgTGZigv4IcGPOZGcLgfqUnbETG/LKUA1cF+y+uonZlbEENqG7l4FfJ/gzHAbUA+sYWhtx3a9bbehug99Hvhd8vGQidHMzgOq3P2lLk8NmRhThSURDGlmVgw8Clzt7g2pz3lwfW9GrvE1s7OBne6+JhPvP0AR4HjgbnefDeyhSzVQJrchQLKe/TyCpDUeKKKHqoShJtPbrT9mdiNB9epDmY4llZkVAjcA38x0LAMVlkTQb3cXmWJmOQRJ4CF3/+/k7B3txcXk/50ZCu9U4Fwz20RQnXYGQX18abKKAzK/LSuBSndvH3V8GUFiGCrbEODDwEZ3r3b3KPDfBNt2KG3Hdr1ttyG1D5nZxcDZwEW+72aooRLj4QRJ/6XkvlMBvGBmYxk6MXYSlkTQb3cXmZCsb/9P4HV3/7eUp5YDn0s+/hzw64MdG4C7X+/uFe4+mWCbPeXuFwErgU9mOj4Ad98ObDGzI5OzzgTWMUS2YdJmYJ6ZFSa/8/YYh8x2TNHbdlsOfDZ51cs8oD6lCumgMrOFBNWV57r73pSnlgMXmFmemU0haJD968GOz91fcffR7j45ue9UAscnf6tDZjt24u6h+AM+SnCFwTvAjZmOJxnTBwmK3i8Da5N/HyWoh38SeBtYAYwYArHOBx5PPp5KsIOtB34J5GU4tuOA1cnt+CugbKhtQ+BbwBvAq8BPgbxMb0fgYYI2iyjBweqS3rYbYARX3r0DvEJwBVSmYlxPUM/evs/8R8ryNyZjfBM4K1Mxdnl+EzAyk9uxvz91MSEiEnJhqRoSEZFeKBGIiIScEoGISMgpEYiIhJwSgYhIyCkRiHRhZnEzW5vyN2gd1pnZ5J56qRTJpLQNVSlyCGt29+MyHYTIwaISgcgAmdkmM/tXM3vFzP5qZh9Izp9sZk8l+5d/0swmJeePSfaX/1Ly75TkqrLN7B4Lxif4g5kVZOxDiaBEINKTgi5VQ4tTnqt395nAvxP0zArwI+ABD/rHfwi4Izn/DuD/ufssgv6PXkvOnwbc6e4zgDrg/LR+GpF+6M5ikS7MrMndi3uYvwk4w903JDsL3O7u5Wa2Cxjn7tHk/G3uPtLMqoEKd29NWcdk4I8eDPyCmX0dyHH3Ww/CRxPpkUoEIvvHe3m8P1pTHsdRW51kmBKByP5ZnPJ/VfLxswS9swJcBPwp+fhJ4EvQMe5zycEKUmR/6ExEpLsCM1ubMv2Eu7dfQlpmZi8TnNVfmJx3JcEIaV8lGC1tSXL+VcBSM7uE4Mz/SwS9VIoMKWojEBmgZBvBXHfflelYRAaTqoZEREJOJQIRkZBTiUBEJOSUCEREQk6JQEQk5JQIRERCTolARCTk/j8BPBED0XTdYwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create submission"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "test_output = model(preprocess(test_all_data, train=False).to_numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "test_output"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(600, 2), dtype=float32, numpy=\n",
       "array([[ 0.1543167 ,  1.8530254 ],\n",
       "       [-0.18921205,  3.475775  ],\n",
       "       [ 0.29773214,  3.4312265 ],\n",
       "       ...,\n",
       "       [ 0.2696903 ,  0.7878944 ],\n",
       "       [ 0.32003763,  2.3561819 ],\n",
       "       [ 0.1747692 ,  2.0952587 ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "pd.DataFrame({\n",
    "    'id':list(range(1, test_output.shape[0]+1)),\n",
    "    'formation_energy_ev_natom': test_output[:, 0],\n",
    "    'bandgap_energy_ev': test_output[:, 1]\n",
    "}).to_csv('submissions/neural_network_op.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.12 64-bit ('ml_project': conda)"
  },
  "interpreter": {
   "hash": "57878c180c9b27ff6feee091cc910bd21e5a74eaa63329fd7bd5866af7456fcd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}